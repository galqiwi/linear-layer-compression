{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    token=\"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\", device_map=\"cuda\", torch_dtype=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "def get_wikitext2(seed, seqlen, nsamples=128):\n",
    "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
    "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", use_fast=True, token=\"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\")\n",
    "\n",
    "    train_input_ids = tokenizer(\"\\n\\n\".join(traindata['text']), return_tensors='pt').input_ids\n",
    "    random.seed(seed)\n",
    "    train_batch = []\n",
    "    for _ in range(nsamples):\n",
    "        i = random.randint(0, train_input_ids.shape[1] - seqlen - 1)\n",
    "        j = i + seqlen\n",
    "        inp = train_input_ids[:, i:j]\n",
    "        tar = inp.clone()\n",
    "        tar[:, :-1] = -100\n",
    "        train_batch.append(inp[0])\n",
    "\n",
    "    test_input_ids = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt').input_ids\n",
    "    test_input_ids = test_input_ids[:, :(test_input_ids.shape[1] // seqlen) *  seqlen]\n",
    "    test_input_ids = test_input_ids.reshape(test_input_ids.shape[1] // seqlen, seqlen)\n",
    "\n",
    "    return torch.stack(train_batch), test_input_ids\n",
    "\n",
    "train_batch, test_input_ids = get_wikitext2(SEED, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_ID = 10\n",
    "LAYER = model.model.layers[LAYER_ID].mlp.down_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HESSIAN = None\n",
    "NUM_SAMPLES = 0\n",
    "INPUTS = []\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_hessian(_, inp, out):\n",
    "    global HESSIAN\n",
    "    global NUM_SAMPLES\n",
    "    inp = inp[0].data # ... x hidden_size\n",
    "    INPUTS.append(inp.clone().cpu())\n",
    "    inp = inp.reshape((-1, inp.shape[-1])) # inputs x hidden_size\n",
    "    inp = inp.t().float() # hidden_size x inputs\n",
    "    NUM_SAMPLES += 1\n",
    "    if HESSIAN is None:\n",
    "        HESSIAN = inp.matmul(inp.t())\n",
    "    else:\n",
    "        HESSIAN += inp.matmul(inp.t())\n",
    "    \n",
    "\n",
    "hook = LAYER.register_forward_hook(\n",
    "    update_hessian\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in trange(train_batch.shape[0]):\n",
    "        input = train_batch[[i]].clone().cuda()\n",
    "        model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = torch.cat(INPUTS, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HESSIAN = HESSIAN / NUM_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(HESSIAN, \"hessian.pt\")\n",
    "torch.save(LAYER.weight.data, \"weight.pt\")\n",
    "torch.save(INPUTS, \"inputs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
