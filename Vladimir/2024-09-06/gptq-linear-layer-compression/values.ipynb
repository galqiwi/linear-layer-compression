{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"meta-llama/Llama-2-7b-hf\"\n",
    "MODEL = \"meta-llama/Meta-Llama-3.1-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c2d40ab5144fb08df99636124dfaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_pt = AutoModelForCausalLM.from_pretrained(\n",
    "    '/mnt/LLM/hub/models--meta-llama--Meta-Llama-3.1-8B/snapshots/13f04ed6f85ef2aa2fd11b960a275c3e31a8069e/',\n",
    "    trust_remote_code=True, torch_dtype=\"auto\", device_map='meta',\n",
    ")\n",
    "\n",
    "def get_module_by_path(model, path):\n",
    "    if path == '':\n",
    "        return model\n",
    "    splitted = path.split('.', 1)\n",
    "    if len(splitted) == 1:\n",
    "        splitted.append('')\n",
    "    next_name, suffix = splitted\n",
    "\n",
    "    try:\n",
    "        next_module = model[int(next_name)]\n",
    "    except:\n",
    "        next_module = getattr(model, next_name)\n",
    "\n",
    "    return get_module_by_path(next_module, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_numel(path):\n",
    "    return get_module_by_path(model_pt, path).weight.numel()\n",
    "\n",
    "total_params = sum(p.numel() for p in model_pt.model.layers.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd \n",
    "import wandb\n",
    "import functools\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_df_from_wandb(path):\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # Project is specified by <entity/project-name>\n",
    "    runs = api.runs(path)\n",
    "    \n",
    "    data_df_lines = []\n",
    "    for run in tqdm.tqdm(runs): \n",
    "        data_df_lines.append({\n",
    "            'Name': run.name,\n",
    "            'Commit': run.commit,\n",
    "            **run.summary._json_dict,\n",
    "            **{k: v for k,v in run.config.items() if not k.startswith('_')},\n",
    "        })\n",
    "    data_df = pd.DataFrame(data_df_lines)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▉              | 501/762 [00:07<00:03, 65.34it/s]"
     ]
    }
   ],
   "source": [
    "data_df = get_df_from_wandb('rock-and-roll/GALQIWI_EDENN_GPTQ')\n",
    "\n",
    "data_df = data_df.rename(columns={\n",
    "    'wikitext2_PPL': 'wikitext2',\n",
    "})\n",
    "\n",
    "data_df = data_df[data_df['model'] == MODEL]\n",
    "\n",
    "data_df = data_df[['layer_idx', 'edenn_d', 'edenn_n', 'wikitext2']]\n",
    "\n",
    "data_df = data_df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "\n",
    "for layer_idx in range(32):\n",
    "    layer_names.append(f'model.layers.{layer_idx}.self_attn.q_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.self_attn.k_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.self_attn.v_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.self_attn.o_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.mlp.gate_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.mlp.up_proj')\n",
    "    layer_names.append(f'model.layers.{layer_idx}.mlp.down_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['layer'] = data_df['layer_idx'].apply(lambda idx: layer_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = sorted(set(data_df['layer']))\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "grids = literal_eval(requests.get(\n",
    "    'https://gist.githubusercontent.com/BlackSamorez/c74f24a648eb8bbfbbbf83f3145ba3c7/raw/ddc3280a4861938e2e2034c29d6802817e26e799/gistfile1.txt'\n",
    ").text)\n",
    "\n",
    "grids.append({\n",
    "    'edenn_d': -1,\n",
    "    'edenn_n': -1,\n",
    "    'bits': 16,\n",
    "    'mse': 0.0,\n",
    "})\n",
    "\n",
    "grids = pd.DataFrame(grids)\n",
    "grids['name'] = grids.apply(\n",
    "    lambda row: 'edenn_d=' + str(row['edenn_d']) + ';edenn_n=' + str(row['edenn_n']),\n",
    "    axis=1,\n",
    ")\n",
    "grids = grids[['bits', 'mse', 'name']]\n",
    "print(len(grids))\n",
    "grids.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse(grid_tuple):\n",
    "    edenn_d, edenn_n = grid_tuple\n",
    "    name = f'edenn_d={edenn_d}.0;edenn_n={edenn_n}.0'\n",
    "    output = grids[grids['name'] == name]['mse'].values[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['mse'] = data_df[['edenn_d', 'edenn_n']].apply(\n",
    "    lambda row: get_mse(tuple(row.values)),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PPL = 5.606692790985107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "scale_by_layer = {}\n",
    "intercept_by_layer = {}\n",
    "\n",
    "for layer_idx, layer in enumerate(layers):\n",
    "    to_fit = data_df[data_df['layer'] == layer]\n",
    "    to_fit = to_fit[to_fit['mse'] < 0.04]\n",
    "    # to_fit = to_fit[to_fit['mse'] < 4 ** -1.7]\n",
    "    # to_fit = to_fit[to_fit['wikitext2'] < 5.640]\n",
    "\n",
    "    slope = LinearRegression(fit_intercept=False).fit(to_fit['mse'].values.reshape(-1, 1), to_fit['wikitext2'] - BASE_PPL).coef_\n",
    "    \n",
    "    scale_by_layer[layer] = slope.item()\n",
    "    intercept_by_layer[layer] = BASE_PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cmap = matplotlib.colormaps[\"plasma\"]\n",
    "\n",
    "plt.scatter([0.0], [5.606692790985107])\n",
    "\n",
    "# for layer_idx, layer in enumerate({'model.layers.0.mlp.down_proj'}):\n",
    "for layer_idx, layer in enumerate(layers):\n",
    "    to_plot = data_df[data_df['layer'] == layer]\n",
    "    to_plot = to_plot[to_plot['mse'] < 0.04]\n",
    "    # to_plot = to_plot[to_plot['wikitext2'] < 5.640]\n",
    "    \n",
    "    plt.scatter(to_plot['mse'], to_plot['wikitext2'], color=cmap(layer_idx / len(layers)))\n",
    "\n",
    "    grid = np.linspace(0, to_plot['mse'].max(), 10)\n",
    "    \n",
    "    plt.plot(grid, intercept_by_layer[layer] + grid * scale_by_layer[layer], color=cmap(layer_idx / len(layers)))\n",
    "\n",
    "\n",
    "plt.title(f'{MODEL}')\n",
    "plt.xlabel('mse')\n",
    "plt.ylabel('ppl')\n",
    "plt.savefig(f'ppl_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scale_by_layer.items(), columns=['layer', 'scale']).sort_values('scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "def find_grids_with_budget(\n",
    "    slopes,    # linear coefficients for [layerwise mse -> metric]\n",
    "    weights,   # linear coefficients for [layer bitwidth -> total bitwidth] (1 / num_blocks for blockwise)\n",
    "    budget,    # upper bound on total bitwidth\n",
    "    grid_bits, # available grid bitwidths\n",
    "    grid_mses  # available grid mses\n",
    ") -> tuple[float, list]:\n",
    "    num_layers = len(slopes)\n",
    "    num_grids = len(grid_bits)\n",
    "    assert len(grid_mses) == num_grids\n",
    "    \n",
    "    solver = pywraplp.Solver.CreateSolver(\"CP-SAT\")\n",
    "\n",
    "    x = {(j, i) : solver.BoolVar(\"name\") for i in range(num_grids) for j in range(num_layers)}\n",
    "    \n",
    "    for j in range(num_layers) : solver.Add(sum(x[(j, i)] for i in range(num_grids)) == 1)\n",
    "    solver.Add(sum(x[(j, i)] * weights[j] * grid_bits[i] for j in range(num_layers) for i in range(num_grids)) <= budget)\n",
    "    solver.Minimize(sum(x[(j, i)] * slopes[j] * grid_mses[i] for j in range(num_layers) for i in range(num_grids)))\n",
    "\n",
    "    status = solver.Solve()\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        avg_bits = sum(x[(j, i)].solution_value() * weights[j] * grid_bits[i] for j in range(num_layers) for i in range(num_grids))\n",
    "        solution = np.asarray([[x[(j, i)].solution_value() for i in range(num_grids)] for j in range(num_layers)])\n",
    "        indices = np.argwhere(solution == 1.0)\n",
    "        assert len(indices) == num_layers\n",
    "        return avg_bits, indices[:,1]\n",
    "    else:\n",
    "        raise Exception(\"Didn't solve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_grids = grids[grids['bits'] > 1.0]\n",
    "\n",
    "layers = sorted(layers)\n",
    "\n",
    "scales = [scale_by_layer[layer] for layer in layers]\n",
    "numels = [get_numel(layer) for layer in layers]\n",
    "grid_names=ok_grids['name'].values\n",
    "grid_bits=ok_grids['bits'].values\n",
    "grid_mses=ok_grids['mse'].values\n",
    "\n",
    "solution_size, solution_idxs = find_grids_with_budget(\n",
    "    scales,\n",
    "    numels,\n",
    "    budget=sum(numels) * 3,\n",
    "    grid_bits=ok_grids['bits'].values,\n",
    "    grid_mses=ok_grids['mse'].values,\n",
    ")\n",
    "\n",
    "print(f'{solution_size / sum(numels)} bits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_names = [grid_names[idx] for idx in solution_idxs]\n",
    "solution_mses = [grid_mses[idx] for idx in solution_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(solution_mses)), solution_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PPL + sum([scale * mse for scale, mse in zip(scales, solution_mses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_by_layer = dict(zip(layers, solution_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 0\n",
    "\n",
    "def to_list(name):\n",
    "    return [round(float(x.split('=')[-1])) for x in name.split(';')]\n",
    "\n",
    "output = []\n",
    "\n",
    "for layer_idx in range(32):\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.self_attn.q_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.self_attn.k_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.self_attn.v_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.self_attn.o_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.mlp.gate_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.mlp.up_proj']))\n",
    "    output.append(to_list(optimal_by_layer[f'model.layers.{layer_idx}.mlp.down_proj']))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add . && git commit -m 'linear-layer-compression' && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
