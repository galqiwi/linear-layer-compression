/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/.conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(

Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.02it/s]
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/.conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for togethercomputer/RedPajama-Data-1T-Sample contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/togethercomputer/RedPajama-Data-1T-Sample
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Starting ...
Ready.
  0%|                                                                                                                                                                                                                                                                      | 0/32 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
0 self_attn.q_proj
Quantizing ...
time 2.87
error 386.066650390625
0 self_attn.k_proj
Quantizing ...
time 2.26
error 344.17425537109375
0 self_attn.v_proj
Quantizing ...
time 2.30
error 19.968936920166016
0 self_attn.o_proj
Quantizing ...
time 2.23
error 0.27071863412857056
0 mlp.gate_proj
Quantizing ...
time 2.59
error 104.43157196044922
0 mlp.up_proj
Quantizing ...
time 2.59
error 99.27603149414062
0 mlp.down_proj
Quantizing ...
time 6.40
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 140, 4096])) that is different to the input size (torch.Size([140, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 257, 4096])) that is different to the input size (torch.Size([257, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 289, 4096])) that is different to the input size (torch.Size([289, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1659, 4096])) that is different to the input size (torch.Size([1659, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1286, 4096])) that is different to the input size (torch.Size([1286, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1219, 4096])) that is different to the input size (torch.Size([1219, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 127, 4096])) that is different to the input size (torch.Size([127, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1490, 4096])) that is different to the input size (torch.Size([1490, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 714, 4096])) that is different to the input size (torch.Size([714, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 918, 4096])) that is different to the input size (torch.Size([918, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 123, 4096])) that is different to the input size (torch.Size([123, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 79, 4096])) that is different to the input size (torch.Size([79, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 887, 4096])) that is different to the input size (torch.Size([887, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 414, 4096])) that is different to the input size (torch.Size([414, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 263, 4096])) that is different to the input size (torch.Size([263, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 48, 4096])) that is different to the input size (torch.Size([48, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 355, 4096])) that is different to the input size (torch.Size([355, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 190, 4096])) that is different to the input size (torch.Size([190, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2776, 4096])) that is different to the input size (torch.Size([2776, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1243, 4096])) that is different to the input size (torch.Size([1243, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1006, 4096])) that is different to the input size (torch.Size([1006, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 747, 4096])) that is different to the input size (torch.Size([747, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 755, 4096])) that is different to the input size (torch.Size([755, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 344, 4096])) that is different to the input size (torch.Size([344, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3023, 4096])) that is different to the input size (torch.Size([3023, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 446, 4096])) that is different to the input size (torch.Size([446, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3543, 4096])) that is different to the input size (torch.Size([3543, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 754, 4096])) that is different to the input size (torch.Size([754, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 890, 4096])) that is different to the input size (torch.Size([890, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 510, 4096])) that is different to the input size (torch.Size([510, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2434, 4096])) that is different to the input size (torch.Size([2434, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 517, 4096])) that is different to the input size (torch.Size([517, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 66, 4096])) that is different to the input size (torch.Size([66, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 884, 4096])) that is different to the input size (torch.Size([884, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 188, 4096])) that is different to the input size (torch.Size([188, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 132, 4096])) that is different to the input size (torch.Size([132, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3424, 4096])) that is different to the input size (torch.Size([3424, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1251, 4096])) that is different to the input size (torch.Size([1251, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 163, 4096])) that is different to the input size (torch.Size([163, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1198, 4096])) that is different to the input size (torch.Size([1198, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 471, 4096])) that is different to the input size (torch.Size([471, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 77, 4096])) that is different to the input size (torch.Size([77, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 878, 4096])) that is different to the input size (torch.Size([878, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 51, 4096])) that is different to the input size (torch.Size([51, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 552, 4096])) that is different to the input size (torch.Size([552, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 151, 4096])) that is different to the input size (torch.Size([151, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 975, 4096])) that is different to the input size (torch.Size([975, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2361, 4096])) that is different to the input size (torch.Size([2361, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 233, 4096])) that is different to the input size (torch.Size([233, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 210, 4096])) that is different to the input size (torch.Size([210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2135, 4096])) that is different to the input size (torch.Size([2135, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 667, 4096])) that is different to the input size (torch.Size([667, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2838, 4096])) that is different to the input size (torch.Size([2838, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 746, 4096])) that is different to the input size (torch.Size([746, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 632, 4096])) that is different to the input size (torch.Size([632, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 366, 4096])) that is different to the input size (torch.Size([366, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 112, 4096])) that is different to the input size (torch.Size([112, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 615, 4096])) that is different to the input size (torch.Size([615, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 323, 4096])) that is different to the input size (torch.Size([323, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1750, 4096])) that is different to the input size (torch.Size([1750, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1220, 4096])) that is different to the input size (torch.Size([1220, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 137, 4096])) that is different to the input size (torch.Size([137, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 149, 4096])) that is different to the input size (torch.Size([149, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 809, 4096])) that is different to the input size (torch.Size([809, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1506, 4096])) that is different to the input size (torch.Size([1506, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2082, 4096])) that is different to the input size (torch.Size([2082, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 254, 4096])) that is different to the input size (torch.Size([254, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 628, 4096])) that is different to the input size (torch.Size([628, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1120, 4096])) that is different to the input size (torch.Size([1120, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 876, 4096])) that is different to the input size (torch.Size([876, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 440, 4096])) that is different to the input size (torch.Size([440, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1362, 4096])) that is different to the input size (torch.Size([1362, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 984, 4096])) that is different to the input size (torch.Size([984, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 367, 4096])) that is different to the input size (torch.Size([367, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 932, 4096])) that is different to the input size (torch.Size([932, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 78, 4096])) that is different to the input size (torch.Size([78, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 89, 4096])) that is different to the input size (torch.Size([89, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 110, 4096])) that is different to the input size (torch.Size([110, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 873, 4096])) that is different to the input size (torch.Size([873, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 448, 4096])) that is different to the input size (torch.Size([448, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 737, 4096])) that is different to the input size (torch.Size([737, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1210, 4096])) that is different to the input size (torch.Size([1210, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2613, 4096])) that is different to the input size (torch.Size([2613, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 305, 4096])) that is different to the input size (torch.Size([305, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 722, 4096])) that is different to the input size (torch.Size([722, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 792, 4096])) that is different to the input size (torch.Size([792, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 191, 4096])) that is different to the input size (torch.Size([191, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 528, 4096])) that is different to the input size (torch.Size([528, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 419, 4096])) that is different to the input size (torch.Size([419, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2594, 4096])) that is different to the input size (torch.Size([2594, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 631, 4096])) that is different to the input size (torch.Size([631, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 721, 4096])) that is different to the input size (torch.Size([721, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 166, 4096])) that is different to the input size (torch.Size([166, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1097, 4096])) that is different to the input size (torch.Size([1097, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 459, 4096])) that is different to the input size (torch.Size([459, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1224, 4096])) that is different to the input size (torch.Size([1224, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3793, 4096])) that is different to the input size (torch.Size([3793, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2066, 4096])) that is different to the input size (torch.Size([2066, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 338, 4096])) that is different to the input size (torch.Size([338, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 207, 4096])) that is different to the input size (torch.Size([207, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1651, 4096])) that is different to the input size (torch.Size([1651, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1033, 4096])) that is different to the input size (torch.Size([1033, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 827, 4096])) that is different to the input size (torch.Size([827, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 359, 4096])) that is different to the input size (torch.Size([359, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1882, 4096])) that is different to the input size (torch.Size([1882, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 436, 4096])) that is different to the input size (torch.Size([436, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 67, 4096])) that is different to the input size (torch.Size([67, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 544, 4096])) that is different to the input size (torch.Size([544, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 402, 4096])) that is different to the input size (torch.Size([402, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1802, 4096])) that is different to the input size (torch.Size([1802, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1102, 4096])) that is different to the input size (torch.Size([1102, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3396, 4096])) that is different to the input size (torch.Size([3396, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 130, 4096])) that is different to the input size (torch.Size([130, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1034, 4096])) that is different to the input size (torch.Size([1034, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 669, 4096])) that is different to the input size (torch.Size([669, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 55, 4096])) that is different to the input size (torch.Size([55, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 604, 4096])) that is different to the input size (torch.Size([604, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 443, 4096])) that is different to the input size (torch.Size([443, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 126, 4096])) that is different to the input size (torch.Size([126, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 160, 4096])) that is different to the input size (torch.Size([160, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 703, 4096])) that is different to the input size (torch.Size([703, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1590, 4096])) that is different to the input size (torch.Size([1590, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1047, 4096])) that is different to the input size (torch.Size([1047, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3802, 4096])) that is different to the input size (torch.Size([3802, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 663, 4096])) that is different to the input size (torch.Size([663, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 165, 4096])) that is different to the input size (torch.Size([165, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1951, 4096])) that is different to the input size (torch.Size([1951, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2013, 4096])) that is different to the input size (torch.Size([2013, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 442, 4096])) that is different to the input size (torch.Size([442, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 668, 4096])) that is different to the input size (torch.Size([668, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 518, 4096])) that is different to the input size (torch.Size([518, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 354, 4096])) that is different to the input size (torch.Size([354, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 120, 4096])) that is different to the input size (torch.Size([120, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 647, 4096])) that is different to the input size (torch.Size([647, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1870, 4096])) that is different to the input size (torch.Size([1870, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 202, 4096])) that is different to the input size (torch.Size([202, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 385, 4096])) that is different to the input size (torch.Size([385, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1340, 4096])) that is different to the input size (torch.Size([1340, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1183, 4096])) that is different to the input size (torch.Size([1183, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 353, 4096])) that is different to the input size (torch.Size([353, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 71, 4096])) that is different to the input size (torch.Size([71, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1529, 4096])) that is different to the input size (torch.Size([1529, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 42, 4096])) that is different to the input size (torch.Size([42, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 91, 4096])) that is different to the input size (torch.Size([91, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 563, 4096])) that is different to the input size (torch.Size([563, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 136, 4096])) that is different to the input size (torch.Size([136, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 972, 4096])) that is different to the input size (torch.Size([972, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1320, 4096])) that is different to the input size (torch.Size([1320, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 265, 4096])) that is different to the input size (torch.Size([265, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1827, 4096])) that is different to the input size (torch.Size([1827, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1014, 4096])) that is different to the input size (torch.Size([1014, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 867, 4096])) that is different to the input size (torch.Size([867, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 256, 4096])) that is different to the input size (torch.Size([256, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 45, 4096])) that is different to the input size (torch.Size([45, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 113, 4096])) that is different to the input size (torch.Size([113, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3964, 4096])) that is different to the input size (torch.Size([3964, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 635, 4096])) that is different to the input size (torch.Size([635, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 74, 4096])) that is different to the input size (torch.Size([74, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1214, 4096])) that is different to the input size (torch.Size([1214, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 276, 4096])) that is different to the input size (torch.Size([276, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 395, 4096])) that is different to the input size (torch.Size([395, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3266, 4096])) that is different to the input size (torch.Size([3266, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 309, 4096])) that is different to the input size (torch.Size([309, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 750, 4096])) that is different to the input size (torch.Size([750, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1146, 4096])) that is different to the input size (torch.Size([1146, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1613, 4096])) that is different to the input size (torch.Size([1613, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 121, 4096])) that is different to the input size (torch.Size([121, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 732, 4096])) that is different to the input size (torch.Size([732, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1377, 4096])) that is different to the input size (torch.Size([1377, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1893, 4096])) that is different to the input size (torch.Size([1893, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 4031, 4096])) that is different to the input size (torch.Size([4031, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 603, 4096])) that is different to the input size (torch.Size([603, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 49, 4096])) that is different to the input size (torch.Size([49, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1368, 4096])) that is different to the input size (torch.Size([1368, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2124, 4096])) that is different to the input size (torch.Size([2124, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 98, 4096])) that is different to the input size (torch.Size([98, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 981, 4096])) that is different to the input size (torch.Size([981, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 597, 4096])) that is different to the input size (torch.Size([597, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 201, 4096])) that is different to the input size (torch.Size([201, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 639, 4096])) that is different to the input size (torch.Size([639, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1725, 4096])) that is different to the input size (torch.Size([1725, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 864, 4096])) that is different to the input size (torch.Size([864, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 69, 4096])) that is different to the input size (torch.Size([69, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 930, 4096])) that is different to the input size (torch.Size([930, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 240, 4096])) that is different to the input size (torch.Size([240, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2318, 4096])) that is different to the input size (torch.Size([2318, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 415, 4096])) that is different to the input size (torch.Size([415, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1692, 4096])) that is different to the input size (torch.Size([1692, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1423, 4096])) that is different to the input size (torch.Size([1423, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 208, 4096])) that is different to the input size (torch.Size([208, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 484, 4096])) that is different to the input size (torch.Size([484, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 908, 4096])) that is different to the input size (torch.Size([908, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 227, 4096])) that is different to the input size (torch.Size([227, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 3515, 4096])) that is different to the input size (torch.Size([3515, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2941, 4096])) that is different to the input size (torch.Size([2941, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1596, 4096])) that is different to the input size (torch.Size([1596, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 850, 4096])) that is different to the input size (torch.Size([850, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1868, 4096])) that is different to the input size (torch.Size([1868, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 304, 4096])) that is different to the input size (torch.Size([304, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1294, 4096])) that is different to the input size (torch.Size([1294, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 269, 4096])) that is different to the input size (torch.Size([269, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 381, 4096])) that is different to the input size (torch.Size([381, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 542, 4096])) that is different to the input size (torch.Size([542, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 534, 4096])) that is different to the input size (torch.Size([534, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1862, 4096])) that is different to the input size (torch.Size([1862, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 328, 4096])) that is different to the input size (torch.Size([328, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1370, 4096])) that is different to the input size (torch.Size([1370, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 341, 4096])) that is different to the input size (torch.Size([341, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 939, 4096])) that is different to the input size (torch.Size([939, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1087, 4096])) that is different to the input size (torch.Size([1087, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 487, 4096])) that is different to the input size (torch.Size([487, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 246, 4096])) that is different to the input size (torch.Size([246, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 992, 4096])) that is different to the input size (torch.Size([992, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 874, 4096])) that is different to the input size (torch.Size([874, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 847, 4096])) that is different to the input size (torch.Size([847, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 194, 4096])) that is different to the input size (torch.Size([194, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2181, 4096])) that is different to the input size (torch.Size([2181, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1060, 4096])) that is different to the input size (torch.Size([1060, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 512, 4096])) that is different to the input size (torch.Size([512, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 785, 4096])) that is different to the input size (torch.Size([785, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2493, 4096])) that is different to the input size (torch.Size([2493, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 154, 4096])) that is different to the input size (torch.Size([154, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 393, 4096])) that is different to the input size (torch.Size([393, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2881, 4096])) that is different to the input size (torch.Size([2881, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1394, 4096])) that is different to the input size (torch.Size([1394, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 520, 4096])) that is different to the input size (torch.Size([520, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 607, 4096])) that is different to the input size (torch.Size([607, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 358, 4096])) that is different to the input size (torch.Size([358, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 999, 4096])) that is different to the input size (torch.Size([999, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 879, 4096])) that is different to the input size (torch.Size([879, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1092, 4096])) that is different to the input size (torch.Size([1092, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 2302, 4096])) that is different to the input size (torch.Size([2302, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 342, 4096])) that is different to the input size (torch.Size([342, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 1950, 4096])) that is different to the input size (torch.Size([1950, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 978, 4096])) that is different to the input size (torch.Size([978, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
/nfs/scistore14/alistgrp/apanfero/CompressionEntropy/gptq/llama2.py:136: UserWarning: Using a target size (torch.Size([1, 197, 4096])) that is different to the input size (torch.Size([197, 4096])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  mse += torch.nn.functional.mse_loss(outs[j][0], out).item()
  3%|███████▉                                                                                                                                                                                                                                                      | 1/32 [00:30<15:49, 30.63s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
1 self_attn.q_proj
Quantizing ...
time 2.68
error 921.22705078125
1 self_attn.k_proj
Quantizing ...
time 2.28
error 941.4420166015625
1 self_attn.v_proj
Quantizing ...
time 2.32
error 90.51322937011719
1 self_attn.o_proj
Quantizing ...
time 2.21
error 2.9437475204467773
1 mlp.gate_proj
Quantizing ...
time 2.64
error 419.00042724609375
1 mlp.up_proj
Quantizing ...
time 2.64
error 364.01641845703125
1 mlp.down_proj
Quantizing ...
time 6.16

  6%|███████████████▉                                                                                                                                                                                                                                              | 2/32 [01:00<15:06, 30.22s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
2 self_attn.q_proj
Quantizing ...
time 2.63
error 2097.765380859375
2 self_attn.k_proj
Quantizing ...
time 2.23
error 2281.38427734375
2 self_attn.v_proj
Quantizing ...
time 2.23
error 537.5040283203125
2 self_attn.o_proj
Quantizing ...
time 2.23
error 5.916988372802734
2 mlp.gate_proj
Quantizing ...
time 2.65
error 1033.1982421875
2 mlp.up_proj
Quantizing ...
time 2.64
error 892.537109375
2 mlp.down_proj
Quantizing ...
time 6.21

  9%|███████████████████████▊                                                                                                                                                                                                                                      | 3/32 [01:30<14:31, 30.06s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
3 self_attn.q_proj
Quantizing ...
time 2.63
error 5309.60888671875
3 self_attn.k_proj
Quantizing ...
time 2.23
error 5517.45947265625
3 self_attn.v_proj
Quantizing ...
time 2.23
error 1399.4564208984375
3 self_attn.o_proj
Quantizing ...
time 2.23
error 10.368717193603516
3 mlp.gate_proj
Quantizing ...
time 2.62
error 1956.3050537109375
3 mlp.up_proj
Quantizing ...
time 2.61
error 1665.445068359375
3 mlp.down_proj
Quantizing ...
time 6.24

 12%|███████████████████████████████▊                                                                                                                                                                                                                              | 4/32 [02:00<13:59, 29.97s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
4 self_attn.q_proj
Quantizing ...
time 2.62
error 5381.3154296875
4 self_attn.k_proj
Quantizing ...
time 2.23
error 5490.7060546875
4 self_attn.v_proj
Quantizing ...
time 2.22
error 1452.3983154296875
4 self_attn.o_proj
Quantizing ...
time 2.23
error 20.946964263916016
4 mlp.gate_proj
Quantizing ...
time 2.57
error 2832.41015625
4 mlp.up_proj
Quantizing ...
time 2.57
error 2275.092041015625
4 mlp.down_proj

Quantizing ...
time 6.25
 16%|███████████████████████████████████████▋                                                                                                                                                                                                                      | 5/32 [02:30<13:27, 29.89s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
5 self_attn.q_proj
Quantizing ...
time 2.61
error 5886.845703125
5 self_attn.k_proj
Quantizing ...
time 2.21
error 6423.658203125
5 self_attn.v_proj
Quantizing ...
time 2.22
error 1727.85107421875
5 self_attn.o_proj
Quantizing ...
time 2.22
error 35.224639892578125
5 mlp.gate_proj
Quantizing ...
time 2.58
error 3580.540771484375
5 mlp.up_proj
Quantizing ...
time 2.57
error 2858.378173828125
5 mlp.down_proj

Quantizing ...
time 6.24
 19%|███████████████████████████████████████████████▋                                                                                                                                                                                                              | 6/32 [02:59<12:55, 29.82s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
6 self_attn.q_proj
Quantizing ...
time 2.63
error 8508.7734375
6 self_attn.k_proj
Quantizing ...
time 2.22
error 8569.1103515625
6 self_attn.v_proj
Quantizing ...
time 2.22
error 2409.58056640625
6 self_attn.o_proj
Quantizing ...
time 2.22
error 44.46124267578125
6 mlp.gate_proj
Quantizing ...
time 2.58
error 4585.0703125
6 mlp.up_proj
Quantizing ...
time 2.57
error 3519.47265625
6 mlp.down_proj

Quantizing ...
time 6.25
 22%|███████████████████████████████████████████████████████▌                                                                                                                                                                                                      | 7/32 [03:29<12:24, 29.80s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
7 self_attn.q_proj
Quantizing ...
time 2.63
error 9158.04296875
7 self_attn.k_proj
Quantizing ...
time 2.22
error 9095.0517578125
7 self_attn.v_proj
Quantizing ...
time 2.22
error 2719.037353515625
7 self_attn.o_proj
Quantizing ...
time 2.21
error 67.26710510253906
7 mlp.gate_proj
Quantizing ...
time 2.56
error 5303.146484375
7 mlp.up_proj
Quantizing ...
time 2.56
error 4102.06640625
7 mlp.down_proj

Quantizing ...
time 6.23
 25%|███████████████████████████████████████████████████████████████▌                                                                                                                                                                                              | 8/32 [03:59<11:54, 29.75s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
8 self_attn.q_proj
Quantizing ...
time 2.61
error 9181.048828125
8 self_attn.k_proj
Quantizing ...
time 2.22
error 9216.427734375
8 self_attn.v_proj
Quantizing ...
time 2.23
error 2838.86328125
8 self_attn.o_proj
Quantizing ...
time 2.20
error 102.87541961669922
8 mlp.gate_proj
Quantizing ...
time 2.55
error 5514.173828125
8 mlp.up_proj
Quantizing ...
time 2.55
error 4512.33837890625
8 mlp.down_proj
Quantizing ...
time 6.23

 28%|███████████████████████████████████████████████████████████████████████▍                                                                                                                                                                                      | 9/32 [04:28<11:23, 29.73s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
9 self_attn.q_proj
Quantizing ...
time 2.61
error 9518.498046875
9 self_attn.k_proj
Quantizing ...
time 2.22
error 10046.6171875
9 self_attn.v_proj
Quantizing ...
time 2.22
error 3080.46435546875
9 self_attn.o_proj
Quantizing ...
time 2.22
error 140.083251953125
9 mlp.gate_proj
Quantizing ...
time 2.55
error 5829.560546875
9 mlp.up_proj
Quantizing ...
time 2.55
error 4939.38330078125
9 mlp.down_proj
Quantizing ...
time 6.23

error 307.2298889160156
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
10 self_attn.q_proj
Quantizing ...
time 2.61
error 9811.4892578125
10 self_attn.k_proj
Quantizing ...
time 2.21
error 10565.798828125
10 self_attn.v_proj
Quantizing ...
time 2.22
error 3171.4599609375
10 self_attn.o_proj
Quantizing ...
time 2.21
error 192.68948364257812
10 mlp.gate_proj
Quantizing ...
time 2.56
error 6079.099609375
10 mlp.up_proj
Quantizing ...
time 2.54
error 5280.64990234375
10 mlp.down_proj

Quantizing ...
time 6.21
 34%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                                      | 11/32 [05:28<10:23, 29.68s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
11 self_attn.q_proj
Quantizing ...
time 2.60
error 10868.546875
11 self_attn.k_proj
Quantizing ...
time 2.20
error 10928.3212890625
11 self_attn.v_proj
Quantizing ...
time 2.22
error 4212.064453125
11 self_attn.o_proj
Quantizing ...
time 2.20
error 199.1275634765625
11 mlp.gate_proj
Quantizing ...
time 2.54
error 6518.69873046875
11 mlp.up_proj
Quantizing ...
time 2.54
error 5804.55322265625
11 mlp.down_proj

Quantizing ...
time 6.20
 38%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                              | 12/32 [05:57<09:52, 29.64s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
12 self_attn.q_proj
Quantizing ...
time 2.61
error 11377.44921875
12 self_attn.k_proj
Quantizing ...
time 2.20
error 12142.556640625
12 self_attn.v_proj
Quantizing ...
time 2.21
error 4127.197265625
12 self_attn.o_proj
Quantizing ...
time 2.20
error 226.73995971679688
12 mlp.gate_proj
Quantizing ...
time 2.55
error 6862.3525390625
12 mlp.up_proj
Quantizing ...
time 2.54
error 6297.7119140625
12 mlp.down_proj
Quantizing ...
time 6.20

 41%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 13/32 [06:27<09:22, 29.62s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
13 self_attn.q_proj
Quantizing ...
time 2.59
error 11526.3212890625
13 self_attn.k_proj
Quantizing ...
time 2.20
error 11931.4658203125
13 self_attn.v_proj
Quantizing ...
time 2.21
error 4513.4814453125
13 self_attn.o_proj
Quantizing ...
time 2.20
error 258.9438171386719
13 mlp.gate_proj
Quantizing ...
time 2.55
error 7203.6142578125
13 mlp.up_proj
Quantizing ...
time 2.55
error 6786.94970703125
13 mlp.down_proj
Quantizing ...
time 6.21

 44%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                              | 14/32 [06:56<08:52, 29.60s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
14 self_attn.q_proj
Quantizing ...
time 2.60
error 11745.8359375
14 self_attn.k_proj
Quantizing ...
time 2.20
error 12512.9052734375
14 self_attn.v_proj
Quantizing ...
time 2.21
error 4530.2412109375
14 self_attn.o_proj
Quantizing ...
time 2.20
error 312.2826843261719
14 mlp.gate_proj
Quantizing ...
time 2.55
error 7875.6591796875
14 mlp.up_proj
Quantizing ...
time 2.54
error 7470.27783203125
14 mlp.down_proj

Quantizing ...
time 6.23
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 15/32 [07:26<08:23, 29.59s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
15 self_attn.q_proj
Quantizing ...
time 2.62
error 11334.8134765625
15 self_attn.k_proj
Quantizing ...
time 2.22
error 12151.7158203125
15 self_attn.v_proj
Quantizing ...
time 2.22
error 4775.20849609375
15 self_attn.o_proj
Quantizing ...
time 2.20
error 341.87542724609375
15 mlp.gate_proj
Quantizing ...
time 2.56
error 8574.66015625
15 mlp.up_proj
Quantizing ...
time 2.55
error 8152.46484375
15 mlp.down_proj

Quantizing ...
time 6.24
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                              | 16/32 [07:55<07:53, 29.61s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
16 self_attn.q_proj
Quantizing ...
time 2.61
error 11740.794921875
16 self_attn.k_proj
Quantizing ...
time 2.19
error 12490.8134765625
16 self_attn.v_proj
Quantizing ...
time 2.20
error 5407.8623046875
16 self_attn.o_proj
Quantizing ...
time 2.20
error 456.00933837890625
16 mlp.gate_proj
Quantizing ...
time 2.55
error 9684.8544921875
16 mlp.up_proj
Quantizing ...
time 2.59
error 9073.080078125
16 mlp.down_proj

Quantizing ...
time 6.47
 53%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                      | 17/32 [08:25<07:25, 29.68s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
17 self_attn.q_proj
Quantizing ...
time 2.65
error 11960.341796875
17 self_attn.k_proj
Quantizing ...
time 2.22
error 12641.8935546875
17 self_attn.v_proj
Quantizing ...
time 2.22
error 5597.251953125
17 self_attn.o_proj
Quantizing ...
time 2.21
error 345.764892578125
17 mlp.gate_proj
Quantizing ...
time 2.57
error 11207.3232421875
17 mlp.up_proj
Quantizing ...
time 2.56
error 10233.541015625
17 mlp.down_proj
Quantizing ...
time 6.25

 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                              | 18/32 [08:55<06:55, 29.69s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
18 self_attn.q_proj
Quantizing ...
time 2.59
error 12948.326171875
18 self_attn.k_proj
Quantizing ...
time 2.20
error 13488.677734375
18 self_attn.v_proj
Quantizing ...
time 2.20
error 6871.0361328125
18 self_attn.o_proj
Quantizing ...
time 2.21
error 394.58941650390625
18 mlp.gate_proj
Quantizing ...
time 2.56
error 12814.58984375
18 mlp.up_proj
Quantizing ...
time 2.55
error 11410.50390625
18 mlp.down_proj
Quantizing ...
time 6.29

 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                      | 19/32 [09:25<06:25, 29.67s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
19 self_attn.q_proj
Quantizing ...
time 2.58
error 12615.9921875
19 self_attn.k_proj
Quantizing ...
time 2.18
error 13195.767578125
19 self_attn.v_proj
Quantizing ...
time 2.20
error 6886.93994140625
19 self_attn.o_proj
Quantizing ...
time 2.21
error 379.0308837890625
19 mlp.gate_proj
Quantizing ...
time 2.56
error 13856.576171875
19 mlp.up_proj
Quantizing ...
time 2.56
error 12267.62109375
19 mlp.down_proj

Quantizing ...
time 6.25
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 20/32 [09:54<05:55, 29.64s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
20 self_attn.q_proj
Quantizing ...
time 2.58
error 12981.54296875
20 self_attn.k_proj
Quantizing ...
time 2.19
error 13561.841796875
20 self_attn.v_proj
Quantizing ...
time 2.19
error 7174.259765625
20 self_attn.o_proj
Quantizing ...
time 2.19
error 418.0291748046875
20 mlp.gate_proj
Quantizing ...
time 2.55
error 14775.31640625
20 mlp.up_proj
Quantizing ...
time 2.54
error 12929.669921875
20 mlp.down_proj

Quantizing ...
time 6.22
 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                       | 21/32 [10:24<05:25, 29.59s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
21 self_attn.q_proj
Quantizing ...
time 2.59
error 13903.2158203125
21 self_attn.k_proj
Quantizing ...
time 2.18
error 14252.927734375
21 self_attn.v_proj
Quantizing ...
time 2.20
error 8405.7998046875
21 self_attn.o_proj
Quantizing ...
time 2.21
error 406.5369873046875
21 mlp.gate_proj
Quantizing ...
time 2.55
error 16052.8212890625
21 mlp.up_proj
Quantizing ...
time 2.55
error 13817.255859375
21 mlp.down_proj
Quantizing ...
time 6.22

 69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 22/32 [10:53<04:55, 29.57s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
22 self_attn.q_proj
Quantizing ...
time 2.58
error 14820.185546875
22 self_attn.k_proj
Quantizing ...
time 2.18
error 15246.7529296875
22 self_attn.v_proj
Quantizing ...
time 2.19
error 8721.5986328125
22 self_attn.o_proj
Quantizing ...
time 2.19
error 503.39447021484375
22 mlp.gate_proj
Quantizing ...
time 2.56
error 17065.45703125
22 mlp.up_proj
Quantizing ...
time 2.55
error 14504.392578125
22 mlp.down_proj
Quantizing ...
time 6.20

 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                       | 23/32 [11:23<04:25, 29.54s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
23 self_attn.q_proj
Quantizing ...
time 2.59
error 16242.2216796875
23 self_attn.k_proj
Quantizing ...
time 2.18
error 16440.896484375
23 self_attn.v_proj
Quantizing ...
time 2.18
error 10591.400390625
23 self_attn.o_proj
Quantizing ...
time 2.20
error 510.3840026855469
23 mlp.gate_proj
Quantizing ...
time 2.56
error 18318.85546875
23 mlp.up_proj
Quantizing ...
time 2.55
error 15737.1494140625
23 mlp.down_proj

Quantizing ...
time 6.20
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 24/32 [11:52<03:56, 29.52s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
24 self_attn.q_proj
Quantizing ...
time 2.58
error 15120.9599609375
24 self_attn.k_proj
Quantizing ...
time 2.19
error 15645.134765625
24 self_attn.v_proj
Quantizing ...
time 2.18
error 10289.361328125
24 self_attn.o_proj
Quantizing ...
time 2.19
error 553.7196044921875
24 mlp.gate_proj
Quantizing ...
time 2.56
error 19414.109375
24 mlp.up_proj
Quantizing ...
time 2.55
error 16689.720703125
24 mlp.down_proj

Quantizing ...
time 6.19
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 25/32 [12:22<03:26, 29.50s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
25 self_attn.q_proj
Quantizing ...
time 2.58
error 17604.203125
25 self_attn.k_proj
Quantizing ...
time 2.18
error 17685.572265625
25 self_attn.v_proj
Quantizing ...
time 2.19
error 12640.28515625
25 self_attn.o_proj
Quantizing ...
time 2.20
error 457.7579650878906
25 mlp.gate_proj
Quantizing ...
time 2.56
error 20799.0234375
25 mlp.up_proj
Quantizing ...
time 2.55
error 17949.74609375
25 mlp.down_proj
Quantizing ...
time 6.22

 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 26/32 [12:51<02:57, 29.50s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
26 self_attn.q_proj
Quantizing ...
time 2.60
error 16707.2578125
26 self_attn.k_proj
Quantizing ...
time 2.19
error 16987.11328125
26 self_attn.v_proj
Quantizing ...
time 2.21
error 12626.17578125
26 self_attn.o_proj
Quantizing ...
time 2.21
error 739.016357421875
26 mlp.gate_proj
Quantizing ...
time 2.57
error 22082.75390625
26 mlp.up_proj
Quantizing ...
time 2.57
error 19121.1171875
26 mlp.down_proj
Quantizing ...
time 6.26

 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 27/32 [13:21<02:27, 29.53s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
27 self_attn.q_proj
Quantizing ...
time 2.58
error 18266.85546875
27 self_attn.k_proj
Quantizing ...
time 2.19
error 18100.42578125
27 self_attn.v_proj
Quantizing ...
time 2.19
error 12917.65625
27 self_attn.o_proj
Quantizing ...
time 2.19
error 727.6055908203125
27 mlp.gate_proj
Quantizing ...
time 2.56
error 23528.953125
27 mlp.up_proj
Quantizing ...
time 2.56
error 20524.2421875
27 mlp.down_proj

Quantizing ...
time 6.25
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 28/32 [13:50<01:58, 29.54s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
28 self_attn.q_proj
Quantizing ...
time 2.64
error 18141.095703125
28 self_attn.k_proj
Quantizing ...
time 2.21
error 17816.494140625
28 self_attn.v_proj
Quantizing ...
time 2.21
error 14231.8818359375
28 self_attn.o_proj
Quantizing ...
time 2.22
error 922.1624755859375
28 mlp.gate_proj
Quantizing ...
time 2.57
error 24435.67578125
28 mlp.up_proj
Quantizing ...
time 2.57
error 21941.00390625
28 mlp.down_proj

Quantizing ...
time 6.30
 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 29/32 [14:20<01:28, 29.60s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
29 self_attn.q_proj
Quantizing ...
time 2.61
error 16171.5439453125
29 self_attn.k_proj
Quantizing ...
time 2.21
error 16011.6640625
29 self_attn.v_proj
Quantizing ...
time 2.21
error 13333.087890625
29 self_attn.o_proj
Quantizing ...
time 2.22
error 810.472412109375
29 mlp.gate_proj
Quantizing ...
time 2.56
error 25364.177734375
29 mlp.up_proj
Quantizing ...
time 2.57
error 23043.41796875
29 mlp.down_proj
Quantizing ...
time 6.33

 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 30/32 [14:50<00:59, 29.65s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
30 self_attn.q_proj
Quantizing ...
time 2.60
error 17800.23046875
30 self_attn.k_proj
Quantizing ...
time 2.21
error 16815.521484375
30 self_attn.v_proj
Quantizing ...
time 2.20
error 14607.423828125
30 self_attn.o_proj
Quantizing ...
time 2.21
error 1112.9022216796875
30 mlp.gate_proj
Quantizing ...
time 2.57
error 26108.703125
30 mlp.up_proj
Quantizing ...
time 2.56
error 23346.92578125
30 mlp.down_proj
Quantizing ...
time 6.36

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 31/32 [15:19<00:29, 29.67s/it]
  0%|                                                                                                                                                                                                                                                                       | 0/1 [00:00<?, ?it/s]
31 self_attn.q_proj
Quantizing ...
time 2.62
error 11769.107421875
31 self_attn.k_proj
Quantizing ...
time 2.22
error 12335.919921875
31 self_attn.v_proj
Quantizing ...
time 2.21
error 8153.4091796875
31 self_attn.o_proj
Quantizing ...
time 2.21
error 1398.4134521484375
31 mlp.gate_proj
Quantizing ...
time 2.58
error 22401.765625
31 mlp.up_proj
Quantizing ...
time 2.58
error 19964.802734375
31 mlp.down_proj
Quantizing ...
time 6.56

error 26250.67578125

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [15:50<00:00, 29.69s/it]
wikitext2
Evaluating ...
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
5.271408557891846