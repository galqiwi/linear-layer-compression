{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a866f38-850a-48a6-b733-4c538f8cb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"meta-llama/Llama-2-7b-hf\"\n",
    "MODEL = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "BASE_PPL = 5.606692790985107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee119188-c644-48b0-82a5-eeaa6c8d81fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b17d33bba0146988aa583f37199a63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_pt = AutoModelForCausalLM.from_pretrained(\n",
    "    '/mnt/LLM/hub/models--meta-llama--Meta-Llama-3.1-8B/snapshots/13f04ed6f85ef2aa2fd11b960a275c3e31a8069e/',\n",
    "    trust_remote_code=True, torch_dtype=\"auto\", device_map='meta',\n",
    ")\n",
    "\n",
    "def get_module_by_path(model, path):\n",
    "    if path == '':\n",
    "        return model\n",
    "    splitted = path.split('.', 1)\n",
    "    if len(splitted) == 1:\n",
    "        splitted.append('')\n",
    "    next_name, suffix = splitted\n",
    "\n",
    "    try:\n",
    "        next_module = model[int(next_name)]\n",
    "    except:\n",
    "        next_module = getattr(model, next_name)\n",
    "\n",
    "    return get_module_by_path(next_module, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c59d67-7da7-424a-aed7-d32dd8ad7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_numel(path):\n",
    "    return get_module_by_path(model_pt, path).weight.numel()\n",
    "\n",
    "total_params = sum(p.numel() for p in model_pt.model.layers.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497e7b0e-90d9-4cd3-ac9f-d826d6d3e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd \n",
    "import wandb\n",
    "import functools\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def get_df_from_wandb(path):\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # Project is specified by <entity/project-name>\n",
    "    runs = api.runs(path)\n",
    "    \n",
    "    data_df_lines = []\n",
    "    for run in tqdm.tqdm(runs): \n",
    "        data_df_lines.append({\n",
    "            'Name': run.name,\n",
    "            'Commit': run.commit,\n",
    "            **run.summary._json_dict,\n",
    "            **{k: v for k,v in run.config.items() if not k.startswith('_')},\n",
    "        })\n",
    "    data_df = pd.DataFrame(data_df_lines)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728442a1-57df-4cca-9123-e3d6d32ac585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_by_layer(exp_path):\n",
    "    data_df = get_df_from_wandb(exp_path)\n",
    "    \n",
    "    data_df = data_df.rename(columns={\n",
    "        'wikitext2_PPL': 'wikitext2',\n",
    "    })\n",
    "    \n",
    "    data_df = data_df[data_df['model'] == MODEL]\n",
    "    data_df = data_df[['layer_idx', 'edenn_d', 'edenn_n', 'wikitext2']]\n",
    "    \n",
    "    data_df = data_df.dropna().copy()\n",
    "    \n",
    "    layer_names = []\n",
    "    \n",
    "    for layer_idx in range(32):\n",
    "        layer_names.append(f'model.layers.{layer_idx}.self_attn.q_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.self_attn.k_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.self_attn.v_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.self_attn.o_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.mlp.gate_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.mlp.up_proj')\n",
    "        layer_names.append(f'model.layers.{layer_idx}.mlp.down_proj')\n",
    "\n",
    "    import requests\n",
    "    from ast import literal_eval\n",
    "    import pandas as pd\n",
    "    \n",
    "    grids = literal_eval(requests.get(\n",
    "        'https://gist.githubusercontent.com/BlackSamorez/c74f24a648eb8bbfbbbf83f3145ba3c7/raw/ddc3280a4861938e2e2034c29d6802817e26e799/gistfile1.txt'\n",
    "    ).text)\n",
    "    \n",
    "    grids.append({\n",
    "        'edenn_d': -1,\n",
    "        'edenn_n': -1,\n",
    "        'bits': 16,\n",
    "        'mse': 0.0,\n",
    "    })\n",
    "    \n",
    "    grids = pd.DataFrame(grids)\n",
    "    grids['name'] = grids.apply(\n",
    "        lambda row: 'edenn_d=' + str(row['edenn_d']) + ';edenn_n=' + str(row['edenn_n']),\n",
    "        axis=1,\n",
    "    )\n",
    "    grids = grids[['bits', 'mse', 'name', 'edenn_d', 'edenn_n']]\n",
    "    def get_mse(grid_tuple):\n",
    "        edenn_d, edenn_n = grid_tuple\n",
    "        name = f'edenn_d={edenn_d}.0;edenn_n={edenn_n}.0'\n",
    "        output = grids[grids['name'] == name]['mse'].values[0]\n",
    "        return output\n",
    "\n",
    "    data_df['mse'] = data_df[['edenn_d', 'edenn_n']].apply(\n",
    "        lambda row: get_mse(tuple(row.values)),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    data_df['layer'] = data_df['layer_idx'].apply(lambda idx: layer_names[idx])\n",
    "    \n",
    "    layers = sorted(set(data_df['layer']))\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    scale_by_layer = {}\n",
    "    intercept_by_layer = {}\n",
    "    \n",
    "    for layer_idx, layer in enumerate(layers):\n",
    "        to_fit = data_df[data_df['layer'] == layer]\n",
    "        to_fit = to_fit[to_fit['mse'] < 0.04]\n",
    "    \n",
    "        slope = LinearRegression(fit_intercept=False).fit(to_fit['mse'].values.reshape(-1, 1), to_fit['wikitext2'] - BASE_PPL).coef_\n",
    "        \n",
    "        scale_by_layer[layer] = slope.item()\n",
    "        intercept_by_layer[layer] = BASE_PPL\n",
    "    \n",
    "    return scale_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16e6fe6-ac1b-455d-8174-b45c881b8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_by_layer_gptq = get_scale_by_layer('rock-and-roll/GALQIWI_EDENN_GPTQ')\n",
    "\n",
    "layers = sorted(scale_by_layer_gptq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e2a7795d-a13f-4eac-8800-f83b1d35fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "import numpy as np\n",
    "\n",
    "def find_grids_with_budget(\n",
    "    slopes,    # INVALID linear coefficients for [layerwise mse -> metric]\n",
    "    numels,   # INVALID linear coefficients for [layer bitwidth -> total bitwidth] (1 / num_blocks for blockwise)\n",
    "    budget,    # INVALID upper bound on total bitwidth\n",
    "    num_codebooks, # INVALID available grid bitwidths\n",
    "    num_bits_per_codebook, # INVALID available grid bitwidths\n",
    "    grid_mses  # INVALID available grid mses\n",
    ") -> tuple[float, list]:\n",
    "    num_layers = len(slopes)\n",
    "    num_grids = len(num_codebooks)\n",
    "    assert len(num_codebooks) == len(num_bits_per_codebook)\n",
    "    assert len(grid_mses) == num_grids\n",
    "    \n",
    "    solver = pywraplp.Solver.CreateSolver(\"CP-SAT\")\n",
    "\n",
    "    x = {(j, i) : solver.BoolVar(\"name\") for i in range(num_grids) for j in range(num_layers)}\n",
    "    \n",
    "    for j in range(num_layers) :\n",
    "        solver.Add(sum(x[(j, i)] for i in range(num_grids)) == 1)\n",
    "    \n",
    "    solver.Add(sum(x[(j, i)] * (\n",
    "        numels[j] * num_codebooks[i] * num_bits_per_codebook[i] / 8 + (2 ** num_bits_per_codebook[i]) * 8 * 16 * num_codebooks[i]\n",
    "    ) for j in range(num_layers) for i in range(num_grids)) <= budget)\n",
    "    \n",
    "    solver.Minimize(sum(x[(j, i)] * slopes[j] * grid_mses[i] for j in range(num_layers) for i in range(num_grids)))\n",
    "\n",
    "    status = solver.Solve()\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        # avg_bits = sum(x[(j, i)].solution_value() * numels[j] * grid_bits[i] for j in range(num_layers) for i in range(num_grids))\n",
    "        solution = np.asarray([[x[(j, i)].solution_value() for i in range(num_grids)] for j in range(num_layers)])\n",
    "        indices = np.argwhere(solution == 1.0)\n",
    "        assert len(indices) == num_layers\n",
    "        return 0.0, indices[:,1]\n",
    "    else:\n",
    "        raise Exception(\"Didn't solve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "301a16aa-bd26-4d1f-8f7f-35c75716b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a2c8eba9-d105-4fb9-a44c-89728eefa186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_codebooks</th>\n",
       "      <th>n_bits_per_codebook</th>\n",
       "      <th>wbits</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3.265625</td>\n",
       "      <td>0.032575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.289062</td>\n",
       "      <td>0.085089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.519531</td>\n",
       "      <td>0.219392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  n_codebooks  n_bits_per_codebook     wbits       mse\n",
       "26          26            2                   11  3.265625  0.032575\n",
       "37          37            3                    6  2.289062  0.085089\n",
       "50          50            4                    3  1.519531  0.219392"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqlm_config = pd.read_csv(StringIO(requests.get('https://gist.githubusercontent.com/galqiwi/bd1ac3d724aa9fc0a058c2d0ee94d541/raw/000ec2847320d5126c856dd3ebf220833e77ceb2/aqlm_configs.csv').text))\n",
    "aqlm_config.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5bc132d1-129d-4406-99e1-3382362b4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqlm_config['wbits'] = aqlm_config.apply(\n",
    "    lambda row: row['n_codebooks'] * row['n_bits_per_codebook'] / 8 + (\n",
    "        2 ** row['n_bits_per_codebook'] * 16 / 4096 / 4096 * 8 * row['n_codebooks']\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2bdc8bd0-1db8-44df-9409-d9a8e2be411b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): 0.919545590877533,\n",
       " (1, 2): 0.8224712610244751,\n",
       " (1, 3): 0.7082441449165344,\n",
       " (1, 4): 0.6006791591644287,\n",
       " (1, 5): 0.5165958404541016,\n",
       " (1, 6): 0.4382802546024322,\n",
       " (1, 7): 0.3716720640659332,\n",
       " (1, 8): 0.3143085539340973,\n",
       " (1, 9): 0.2638692259788513,\n",
       " (1, 10): 0.2200138568878173,\n",
       " (1, 11): 0.1806469708681106,\n",
       " (1, 12): 0.1454421728849411,\n",
       " (1, 13): 0.1135108694434166,\n",
       " (1, 14): 0.0839976817369461,\n",
       " (1, 15): 0.0562547110021114,\n",
       " (1, 16): 0.028201874345541,\n",
       " (2, 1): 0.8393333554267883,\n",
       " (2, 2): 0.644393801689148,\n",
       " (2, 3): 0.4761597216129303,\n",
       " (2, 4): 0.3545707464218139,\n",
       " (2, 5): 0.2630593776702881,\n",
       " (2, 6): 0.1916685402393341,\n",
       " (2, 7): 0.1385392993688583,\n",
       " (2, 8): 0.0993240177631378,\n",
       " (2, 9): 0.0706783756613731,\n",
       " (2, 10): 0.0486727841198444,\n",
       " (2, 11): 0.0325747616589069,\n",
       " (2, 12): 0.0205543953925371,\n",
       " (2, 13): 0.0119948349893093,\n",
       " (2, 14): 0.0060074115172028,\n",
       " (2, 15): 0.0022380454465746,\n",
       " (2, 16): 0.0002627053763717,\n",
       " (3, 1): 0.7597394585609436,\n",
       " (3, 2): 0.4846304357051849,\n",
       " (3, 3): 0.3175719380378723,\n",
       " (3, 4): 0.211075022816658,\n",
       " (3, 5): 0.1360477656126022,\n",
       " (3, 6): 0.0850889980792999,\n",
       " (3, 7): 0.0526263490319252,\n",
       " (3, 8): 0.0323111340403556,\n",
       " (3, 9): 0.0193628016859293,\n",
       " (3, 10): 0.0111018912866711,\n",
       " (3, 11): 0.0059479842893779,\n",
       " (3, 12): 0.0029242213349789,\n",
       " (3, 13): 0.0012605496449396,\n",
       " (3, 14): 0.0004293757956475,\n",
       " (3, 15): 7.36227520974353e-05,\n",
       " (3, 16): 1.8091387762875225e-11,\n",
       " (4, 1): 0.6794429421424866,\n",
       " (4, 2): 0.385371595621109,\n",
       " (4, 3): 0.2193915992975235,\n",
       " (4, 4): 0.1265846639871597,\n",
       " (4, 5): 0.0711989849805831,\n",
       " (4, 6): 0.0387304350733757,\n",
       " (4, 7): 0.0208387859165668,\n",
       " (4, 8): 0.010958339087665,\n",
       " (4, 9): 0.0055199139751493,\n",
       " (4, 10): 0.0025825568009167,\n",
       " (4, 11): 0.0011170415673404,\n",
       " (4, 12): 0.0004258627304807,\n",
       " (4, 13): 0.00013441266492,\n",
       " (4, 14): 3.031856431334745e-05,\n",
       " (4, 15): 5.611464075627737e-07,\n",
       " (4, 16): 5.14173098054016e-06}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_by_aqlm_config = dict(zip([tuple(k) for k in aqlm_config[['n_codebooks', 'n_bits_per_codebook']].values], aqlm_config['mse']))\n",
    "mse_by_aqlm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "15c66fce-73e2-406a-b752-d5cb08317104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_codebooks</th>\n",
       "      <th>n_bits_per_codebook</th>\n",
       "      <th>wbits</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125015</td>\n",
       "      <td>0.919546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250031</td>\n",
       "      <td>0.822471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375061</td>\n",
       "      <td>0.708244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500122</td>\n",
       "      <td>0.600679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625244</td>\n",
       "      <td>0.516596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750488</td>\n",
       "      <td>0.438280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875977</td>\n",
       "      <td>0.371672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.001953</td>\n",
       "      <td>0.314309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.128906</td>\n",
       "      <td>0.263869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.257812</td>\n",
       "      <td>0.220014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.390625</td>\n",
       "      <td>0.180647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>0.145442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.113511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.083998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.056255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.028202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  n_codebooks  n_bits_per_codebook     wbits       mse\n",
       "0            0            1                    1  0.125015  0.919546\n",
       "1            1            1                    2  0.250031  0.822471\n",
       "2            2            1                    3  0.375061  0.708244\n",
       "3            3            1                    4  0.500122  0.600679\n",
       "4            4            1                    5  0.625244  0.516596\n",
       "5            5            1                    6  0.750488  0.438280\n",
       "6            6            1                    7  0.875977  0.371672\n",
       "7            7            1                    8  1.001953  0.314309\n",
       "8            8            1                    9  1.128906  0.263869\n",
       "9            9            1                   10  1.257812  0.220014\n",
       "10          10            1                   11  1.390625  0.180647\n",
       "11          11            1                   12  1.531250  0.145442\n",
       "12          12            1                   13  1.687500  0.113511\n",
       "13          13            1                   14  1.875000  0.083998\n",
       "14          14            1                   15  2.125000  0.056255\n",
       "15          15            1                   16  2.500000  0.028202"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqlm_config.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f14d7a-7d0c-49f2-8ac5-dac540cf5c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04aaac-04dc-45bc-84e6-b76ab5ce5319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "41d6ca74-37cc-4ab1-a228-11c6c15b9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqlm_config = pd.concat([\n",
    "#     aqlm_config,\n",
    "#     pd.DataFrame([{\n",
    "#         'n_codebooks': -1,\n",
    "#         'n_bits_per_codebook': -1,\n",
    "#         'wbits': 16,\n",
    "#         'mse': 4 ** -16,\n",
    "#     }])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "40fac934-bae3-4c62-a4b8-970472d82257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_codebooks</th>\n",
       "      <th>n_bits_per_codebook</th>\n",
       "      <th>wbits</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125015</td>\n",
       "      <td>9.195456e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250031</td>\n",
       "      <td>8.224713e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.375061</td>\n",
       "      <td>7.082441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500122</td>\n",
       "      <td>6.006792e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.625244</td>\n",
       "      <td>5.165958e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>4.258627e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.344127e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.031856e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>5.611464e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.141731e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  n_codebooks  n_bits_per_codebook      wbits           mse\n",
       "0            0            1                    1   0.125015  9.195456e-01\n",
       "1            1            1                    2   0.250031  8.224713e-01\n",
       "2            2            1                    3   0.375061  7.082441e-01\n",
       "3            3            1                    4   0.500122  6.006792e-01\n",
       "4            4            1                    5   0.625244  5.165958e-01\n",
       "..         ...          ...                  ...        ...           ...\n",
       "59          59            4                   12   6.125000  4.258627e-04\n",
       "60          60            4                   13   6.750000  1.344127e-04\n",
       "61          61            4                   14   7.500000  3.031856e-05\n",
       "62          62            4                   15   8.500000  5.611464e-07\n",
       "63          63            4                   16  10.000000  5.141731e-06\n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqlm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c682bcab-8448-4fbd-8bdb-7d7a8207dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_aqlm_config = aqlm_config[((aqlm_config['n_codebooks'] >= 2) & (aqlm_config['n_bits_per_codebook'] >= 10)) | (aqlm_config['n_codebooks'] >= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dfc518cd-faec-47fb-aa90-cb5cd4db46e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 bits\n"
     ]
    }
   ],
   "source": [
    "layers = sorted(layers)\n",
    "\n",
    "scales = [scale_by_layer_gptq[layer] for layer in layers]\n",
    "numels = [get_numel(layer) for layer in layers]\n",
    "# num_codebooks = aqlm\n",
    "\n",
    "solution_size, solution_idxs = find_grids_with_budget(\n",
    "    scales,\n",
    "    numels,\n",
    "    budget=sum(numels) * 3,\n",
    "    num_codebooks=ok_aqlm_config['n_codebooks'].values,\n",
    "    num_bits_per_codebook=ok_aqlm_config['n_bits_per_codebook'].values,\n",
    "    grid_mses=ok_aqlm_config['mse'].values,\n",
    ")\n",
    "\n",
    "print(f'{solution_size / sum(numels)} bits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "933a6570-bfb2-46f0-aa37-5d2982239eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5400175584965011"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([scale * ok_aqlm_config['mse'].values[solution_idx] for scale, solution_idx in zip(scales, solution_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c293d5a1-8624-425f-95c1-2a778a19ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5994111631069067"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([scale * mse_by_aqlm_config[(2, 12)] for scale, solution_idx in zip(scales, solution_idxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "dc5c0208-50df-4da7-9943-7e9a4d36f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.layers.0.mlp.down_proj': (2, 14),\n",
       " 'model.layers.0.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.0.mlp.up_proj': (2, 10),\n",
       " 'model.layers.0.self_attn.k_proj': (2, 10),\n",
       " 'model.layers.0.self_attn.o_proj': (2, 10),\n",
       " 'model.layers.0.self_attn.q_proj': (3, 5),\n",
       " 'model.layers.0.self_attn.v_proj': (2, 12),\n",
       " 'model.layers.1.mlp.down_proj': (2, 13),\n",
       " 'model.layers.1.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.1.mlp.up_proj': (2, 12),\n",
       " 'model.layers.1.self_attn.k_proj': (2, 11),\n",
       " 'model.layers.1.self_attn.o_proj': (2, 14),\n",
       " 'model.layers.1.self_attn.q_proj': (3, 5),\n",
       " 'model.layers.1.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.10.mlp.down_proj': (2, 11),\n",
       " 'model.layers.10.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.10.mlp.up_proj': (2, 11),\n",
       " 'model.layers.10.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.10.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.10.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.10.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.11.mlp.down_proj': (2, 10),\n",
       " 'model.layers.11.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.11.mlp.up_proj': (2, 11),\n",
       " 'model.layers.11.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.11.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.11.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.11.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.12.mlp.down_proj': (2, 11),\n",
       " 'model.layers.12.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.12.mlp.up_proj': (2, 11),\n",
       " 'model.layers.12.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.12.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.12.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.12.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.13.mlp.down_proj': (2, 12),\n",
       " 'model.layers.13.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.13.mlp.up_proj': (2, 11),\n",
       " 'model.layers.13.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.13.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.13.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.13.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.14.mlp.down_proj': (2, 12),\n",
       " 'model.layers.14.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.14.mlp.up_proj': (2, 12),\n",
       " 'model.layers.14.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.14.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.14.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.14.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.15.mlp.down_proj': (2, 12),\n",
       " 'model.layers.15.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.15.mlp.up_proj': (2, 12),\n",
       " 'model.layers.15.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.15.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.15.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.15.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.16.mlp.down_proj': (2, 13),\n",
       " 'model.layers.16.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.16.mlp.up_proj': (2, 12),\n",
       " 'model.layers.16.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.16.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.16.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.16.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.17.mlp.down_proj': (2, 13),\n",
       " 'model.layers.17.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.17.mlp.up_proj': (2, 12),\n",
       " 'model.layers.17.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.17.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.17.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.17.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.18.mlp.down_proj': (2, 13),\n",
       " 'model.layers.18.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.18.mlp.up_proj': (2, 13),\n",
       " 'model.layers.18.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.18.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.18.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.18.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.19.mlp.down_proj': (2, 13),\n",
       " 'model.layers.19.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.19.mlp.up_proj': (2, 12),\n",
       " 'model.layers.19.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.19.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.19.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.19.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.2.mlp.down_proj': (2, 12),\n",
       " 'model.layers.2.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.2.mlp.up_proj': (2, 11),\n",
       " 'model.layers.2.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.2.self_attn.o_proj': (2, 10),\n",
       " 'model.layers.2.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.2.self_attn.v_proj': (3, 13),\n",
       " 'model.layers.20.mlp.down_proj': (2, 13),\n",
       " 'model.layers.20.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.20.mlp.up_proj': (2, 13),\n",
       " 'model.layers.20.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.20.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.20.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.20.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.21.mlp.down_proj': (2, 13),\n",
       " 'model.layers.21.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.21.mlp.up_proj': (2, 12),\n",
       " 'model.layers.21.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.21.self_attn.o_proj': (2, 10),\n",
       " 'model.layers.21.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.21.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.22.mlp.down_proj': (2, 13),\n",
       " 'model.layers.22.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.22.mlp.up_proj': (2, 12),\n",
       " 'model.layers.22.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.22.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.22.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.22.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.23.mlp.down_proj': (2, 13),\n",
       " 'model.layers.23.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.23.mlp.up_proj': (2, 12),\n",
       " 'model.layers.23.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.23.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.23.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.23.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.24.mlp.down_proj': (2, 13),\n",
       " 'model.layers.24.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.24.mlp.up_proj': (2, 12),\n",
       " 'model.layers.24.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.24.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.24.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.24.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.25.mlp.down_proj': (2, 13),\n",
       " 'model.layers.25.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.25.mlp.up_proj': (2, 12),\n",
       " 'model.layers.25.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.25.self_attn.o_proj': (2, 10),\n",
       " 'model.layers.25.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.25.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.26.mlp.down_proj': (2, 12),\n",
       " 'model.layers.26.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.26.mlp.up_proj': (2, 12),\n",
       " 'model.layers.26.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.26.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.26.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.26.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.27.mlp.down_proj': (2, 12),\n",
       " 'model.layers.27.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.27.mlp.up_proj': (2, 12),\n",
       " 'model.layers.27.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.27.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.27.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.27.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.28.mlp.down_proj': (2, 12),\n",
       " 'model.layers.28.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.28.mlp.up_proj': (2, 12),\n",
       " 'model.layers.28.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.28.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.28.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.28.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.29.mlp.down_proj': (2, 12),\n",
       " 'model.layers.29.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.29.mlp.up_proj': (2, 12),\n",
       " 'model.layers.29.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.29.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.29.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.29.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.3.mlp.down_proj': (2, 12),\n",
       " 'model.layers.3.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.3.mlp.up_proj': (2, 12),\n",
       " 'model.layers.3.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.3.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.3.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.3.self_attn.v_proj': (3, 13),\n",
       " 'model.layers.30.mlp.down_proj': (2, 11),\n",
       " 'model.layers.30.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.30.mlp.up_proj': (2, 12),\n",
       " 'model.layers.30.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.30.self_attn.o_proj': (2, 11),\n",
       " 'model.layers.30.self_attn.q_proj': (2, 10),\n",
       " 'model.layers.30.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.31.mlp.down_proj': (2, 14),\n",
       " 'model.layers.31.mlp.gate_proj': (2, 14),\n",
       " 'model.layers.31.mlp.up_proj': (2, 15),\n",
       " 'model.layers.31.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.31.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.31.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.31.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.4.mlp.down_proj': (2, 13),\n",
       " 'model.layers.4.mlp.gate_proj': (2, 12),\n",
       " 'model.layers.4.mlp.up_proj': (2, 12),\n",
       " 'model.layers.4.self_attn.k_proj': (3, 11),\n",
       " 'model.layers.4.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.4.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.4.self_attn.v_proj': (3, 13),\n",
       " 'model.layers.5.mlp.down_proj': (2, 12),\n",
       " 'model.layers.5.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.5.mlp.up_proj': (2, 12),\n",
       " 'model.layers.5.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.5.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.5.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.5.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.6.mlp.down_proj': (2, 12),\n",
       " 'model.layers.6.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.6.mlp.up_proj': (2, 12),\n",
       " 'model.layers.6.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.6.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.6.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.6.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.7.mlp.down_proj': (2, 12),\n",
       " 'model.layers.7.mlp.gate_proj': (2, 11),\n",
       " 'model.layers.7.mlp.up_proj': (2, 12),\n",
       " 'model.layers.7.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.7.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.7.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.7.self_attn.v_proj': (3, 11),\n",
       " 'model.layers.8.mlp.down_proj': (2, 12),\n",
       " 'model.layers.8.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.8.mlp.up_proj': (2, 11),\n",
       " 'model.layers.8.self_attn.k_proj': (2, 12),\n",
       " 'model.layers.8.self_attn.o_proj': (2, 12),\n",
       " 'model.layers.8.self_attn.q_proj': (2, 12),\n",
       " 'model.layers.8.self_attn.v_proj': (3, 12),\n",
       " 'model.layers.9.mlp.down_proj': (2, 12),\n",
       " 'model.layers.9.mlp.gate_proj': (2, 10),\n",
       " 'model.layers.9.mlp.up_proj': (2, 11),\n",
       " 'model.layers.9.self_attn.k_proj': (2, 13),\n",
       " 'model.layers.9.self_attn.o_proj': (2, 13),\n",
       " 'model.layers.9.self_attn.q_proj': (2, 11),\n",
       " 'model.layers.9.self_attn.v_proj': (3, 11)}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_conf = dict(list([(layer, (ok_aqlm_config['n_codebooks'].values[idx], ok_aqlm_config['n_bits_per_codebook'].values[idx])) for layer, idx in zip(layers, solution_idxs)]))\n",
    "opt_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "32dd824b-d568-49aa-b82f-212ebd9b8ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0.mlp.down_proj 3.5714285714285716 2 14\n",
      "model.layers.0.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.0.mlp.up_proj 2.5044642857142856 2 10\n",
      "model.layers.0.self_attn.k_proj 2.5625 2 10\n",
      "model.layers.0.self_attn.o_proj 2.515625 2 10\n",
      "model.layers.0.self_attn.q_proj 1.875732421875 3 5\n",
      "model.layers.0.self_attn.v_proj 3.25 2 12\n",
      "model.layers.1.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.1.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.1.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.1.self_attn.k_proj 2.875 2 11\n",
      "model.layers.1.self_attn.o_proj 3.75 2 14\n",
      "model.layers.1.self_attn.q_proj 1.875732421875 3 5\n",
      "model.layers.1.self_attn.v_proj 4.875 3 12\n",
      "model.layers.10.mlp.down_proj 2.7589285714285716 2 11\n",
      "model.layers.10.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.10.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.10.self_attn.k_proj 3.75 2 13\n",
      "model.layers.10.self_attn.o_proj 3.375 2 13\n",
      "model.layers.10.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.10.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.11.mlp.down_proj 2.5044642857142856 2 10\n",
      "model.layers.11.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.11.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.11.self_attn.k_proj 3.75 2 13\n",
      "model.layers.11.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.11.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.11.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.12.mlp.down_proj 2.7589285714285716 2 11\n",
      "model.layers.12.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.12.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.12.self_attn.k_proj 3.75 2 13\n",
      "model.layers.12.self_attn.o_proj 3.375 2 13\n",
      "model.layers.12.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.12.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.13.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.13.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.13.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.13.self_attn.k_proj 3.75 2 13\n",
      "model.layers.13.self_attn.o_proj 3.375 2 13\n",
      "model.layers.13.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.13.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.14.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.14.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.14.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.14.self_attn.k_proj 3.75 2 13\n",
      "model.layers.14.self_attn.o_proj 3.375 2 13\n",
      "model.layers.14.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.14.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.15.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.15.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.15.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.15.self_attn.k_proj 3.75 2 13\n",
      "model.layers.15.self_attn.o_proj 3.375 2 13\n",
      "model.layers.15.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.15.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.16.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.16.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.16.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.16.self_attn.k_proj 3.25 2 12\n",
      "model.layers.16.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.16.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.16.self_attn.v_proj 4.875 3 12\n",
      "model.layers.17.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.17.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.17.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.17.self_attn.k_proj 3.75 2 13\n",
      "model.layers.17.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.17.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.17.self_attn.v_proj 4.875 3 12\n",
      "model.layers.18.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.18.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.18.mlp.up_proj 3.2857142857142856 2 13\n",
      "model.layers.18.self_attn.k_proj 3.75 2 13\n",
      "model.layers.18.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.18.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.18.self_attn.v_proj 4.875 3 12\n",
      "model.layers.19.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.19.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.19.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.19.self_attn.k_proj 3.25 2 12\n",
      "model.layers.19.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.19.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.19.self_attn.v_proj 4.875 3 12\n",
      "model.layers.2.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.2.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.2.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.2.self_attn.k_proj 3.25 2 12\n",
      "model.layers.2.self_attn.o_proj 2.515625 2 10\n",
      "model.layers.2.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.2.self_attn.v_proj 5.625 3 13\n",
      "model.layers.20.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.20.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.20.mlp.up_proj 3.2857142857142856 2 13\n",
      "model.layers.20.self_attn.k_proj 3.25 2 12\n",
      "model.layers.20.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.20.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.20.self_attn.v_proj 4.875 3 12\n",
      "model.layers.21.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.21.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.21.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.21.self_attn.k_proj 3.25 2 12\n",
      "model.layers.21.self_attn.o_proj 2.515625 2 10\n",
      "model.layers.21.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.21.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.22.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.22.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.22.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.22.self_attn.k_proj 3.25 2 12\n",
      "model.layers.22.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.22.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.22.self_attn.v_proj 4.875 3 12\n",
      "model.layers.23.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.23.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.23.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.23.self_attn.k_proj 3.25 2 12\n",
      "model.layers.23.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.23.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.23.self_attn.v_proj 4.875 3 12\n",
      "model.layers.24.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.24.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.24.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.24.self_attn.k_proj 3.25 2 12\n",
      "model.layers.24.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.24.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.24.self_attn.v_proj 4.875 3 12\n",
      "model.layers.25.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.25.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.25.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.25.self_attn.k_proj 3.75 2 13\n",
      "model.layers.25.self_attn.o_proj 2.515625 2 10\n",
      "model.layers.25.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.25.self_attn.v_proj 4.875 3 12\n",
      "model.layers.26.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.26.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.26.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.26.self_attn.k_proj 3.75 2 13\n",
      "model.layers.26.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.26.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.26.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.27.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.27.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.27.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.27.self_attn.k_proj 3.25 2 12\n",
      "model.layers.27.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.27.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.27.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.28.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.28.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.28.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.28.self_attn.k_proj 3.75 2 13\n",
      "model.layers.28.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.28.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.28.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.29.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.29.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.29.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.29.self_attn.k_proj 3.75 2 13\n",
      "model.layers.29.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.29.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.29.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.3.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.3.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.3.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.3.self_attn.k_proj 3.25 2 12\n",
      "model.layers.3.self_attn.o_proj 3.375 2 13\n",
      "model.layers.3.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.3.self_attn.v_proj 5.625 3 13\n",
      "model.layers.30.mlp.down_proj 2.7589285714285716 2 11\n",
      "model.layers.30.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.30.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.30.self_attn.k_proj 3.25 2 12\n",
      "model.layers.30.self_attn.o_proj 2.78125 2 11\n",
      "model.layers.30.self_attn.q_proj 2.515625 2 10\n",
      "model.layers.30.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.31.mlp.down_proj 3.5714285714285716 2 14\n",
      "model.layers.31.mlp.gate_proj 3.5714285714285716 2 14\n",
      "model.layers.31.mlp.up_proj 3.892857142857143 2 15\n",
      "model.layers.31.self_attn.k_proj 3.25 2 12\n",
      "model.layers.31.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.31.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.31.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.4.mlp.down_proj 3.2857142857142856 2 13\n",
      "model.layers.4.mlp.gate_proj 3.017857142857143 2 12\n",
      "model.layers.4.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.4.self_attn.k_proj 4.3125 3 11\n",
      "model.layers.4.self_attn.o_proj 3.375 2 13\n",
      "model.layers.4.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.4.self_attn.v_proj 5.625 3 13\n",
      "model.layers.5.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.5.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.5.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.5.self_attn.k_proj 3.75 2 13\n",
      "model.layers.5.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.5.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.5.self_attn.v_proj 4.875 3 12\n",
      "model.layers.6.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.6.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.6.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.6.self_attn.k_proj 3.25 2 12\n",
      "model.layers.6.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.6.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.6.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.7.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.7.mlp.gate_proj 2.7589285714285716 2 11\n",
      "model.layers.7.mlp.up_proj 3.017857142857143 2 12\n",
      "model.layers.7.self_attn.k_proj 3.75 2 13\n",
      "model.layers.7.self_attn.o_proj 3.375 2 13\n",
      "model.layers.7.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.7.self_attn.v_proj 4.3125 3 11\n",
      "model.layers.8.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.8.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.8.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.8.self_attn.k_proj 3.25 2 12\n",
      "model.layers.8.self_attn.o_proj 3.0625 2 12\n",
      "model.layers.8.self_attn.q_proj 3.0625 2 12\n",
      "model.layers.8.self_attn.v_proj 4.875 3 12\n",
      "model.layers.9.mlp.down_proj 3.017857142857143 2 12\n",
      "model.layers.9.mlp.gate_proj 2.5044642857142856 2 10\n",
      "model.layers.9.mlp.up_proj 2.7589285714285716 2 11\n",
      "model.layers.9.self_attn.k_proj 3.75 2 13\n",
      "model.layers.9.self_attn.o_proj 3.375 2 13\n",
      "model.layers.9.self_attn.q_proj 2.78125 2 11\n",
      "model.layers.9.self_attn.v_proj 4.3125 3 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9998532863849765"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bits = 0\n",
    "\n",
    "for layer in layers:\n",
    "    n_codebooks, n_bits_per_codebook = opt_conf[layer]\n",
    "    # n_codebooks, n_bits_per_codebook = 2, 12\n",
    "    layer_bits = get_numel(layer) * n_bits_per_codebook * n_codebooks / 8\n",
    "    layer_bits += 2 ** n_bits_per_codebook * 16 * 8 * n_codebooks\n",
    "    print(layer, layer_bits / get_numel(layer), n_codebooks, n_bits_per_codebook)\n",
    "    n_bits += layer_bits\n",
    "\n",
    "n_bits / total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "044f50f8-2bf9-4275-b5aa-e645ac687fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0077173881436106\t0.5240948105743083\n",
      "3.0277041480654763\t0.3499951586643389\n",
      "2.979858845581502\t0.3550153634281454\n",
      "2.9803586600629974\t0.4940040494336869\n",
      "2.994342964872829\t0.5239372041646434\n",
      "3.0005076671060795\t0.5218408296703543\n",
      "3.0011667862127793\t0.5226888026690527\n",
      "3.0000811782723327\t0.5247808469117028\n",
      "3.004578696882754\t0.5213248232135047\n",
      "3.0045399251705955\t0.522476137738773\n",
      "3.0067886844758065\t0.5218502323291769\n",
      "3.009076215493176\t0.5207743051290842\n",
      "3.0067886844758065\t0.5221113940491396\n",
      "3.003842034351737\t0.5223924931937499\n",
      "3.001593275046526\t0.5218110293307012\n",
      "2.999383287453474\t0.5235161635247775\n",
      "2.9984915380738215\t0.5240817005047229\n",
      "2.998181364376551\t0.5232810860634712\n",
      "2.9958550616470223\t0.5239559447847765\n",
      "2.996940669587469\t0.5237897902601301\n",
      "2.99527348596464\t0.5244701211560231\n",
      "2.9986078532102978\t0.5228569377939412\n",
      "2.9969018978753104\t0.5231169481267809\n",
      "2.9975997886941688\t0.5227707796497779\n",
      "2.9975997886941688\t0.5238492574573457\n",
      "2.997948734103598\t0.5237213070274888\n",
      "2.999964863135856\t0.5216894487234751\n",
      "2.999577146014268\t0.5233276851647789\n",
      "2.999305744029156\t0.5234784277576807\n",
      "2.9986078532102978\t0.5239576645098942\n",
      "3.0025237961383375\t0.5223086358789214\n",
      "2.981703386709057\t0.529384201621747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bits = 0\n",
    "\n",
    "for block_idx in range(32):\n",
    "    n_block_bits = 0\n",
    "    n_block_numel = 0\n",
    "    block_err = 0\n",
    "    for layer in layers:\n",
    "        if layer.startswith(f'model.layers.{block_idx}'):\n",
    "            continue\n",
    "        n_codebooks, n_bits_per_codebook = opt_conf[layer]\n",
    "\n",
    "        # n_codebooks, n_bits_per_codebook = 2, 12\n",
    "        \n",
    "        layer_bits = get_numel(layer) * n_bits_per_codebook * n_codebooks / 8\n",
    "        layer_bits += 2 ** n_bits_per_codebook * 16 * 8 * n_codebooks\n",
    "        # print(layer, layer_bits / get_numel(layer), n_codebooks, n_bits_per_codebook)\n",
    "        block_err += scale_by_layer_gptq[layer] * mse_by_aqlm_config[(n_codebooks, n_bits_per_codebook)]\n",
    "        n_block_bits += layer_bits\n",
    "        n_block_numel += get_numel(layer)\n",
    "    print(n_block_bits / n_block_numel, block_err, sep='\\t')\n",
    "\n",
    "n_bits / total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cf85dafc-b0f1-4992-a993-adae12399033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f881317-dd96-41a8-9c94-ccf81a5e31dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464cd45-cbdc-440c-a0ad-c91a2f450f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c2c46-2773-4fe7-be51-cfb579ba32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f4a58-866e-4245-ab79-917b327cd5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e7ff7-4b64-4700-b5b6-74186f44f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03052ad3-e085-4242-a6ec-efb31242baf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c3225-4a38-4497-9ecb-64fde32fc08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483afb3-8189-47bc-bf36-c5ccf1db8592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfe547-3e91-4760-b19f-5a97a3f515bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653c3b3-33d1-4d33-9e4e-9236b028e429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56299303-829b-4f15-8db1-930ec16c5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantizing module mlp.down_proj of layer 0\n",
    "# print(f\"Quantizing module {sublayer_name} of layer {layer_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5470fff-e333-4a01-8d82-a90b3fca2843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.layers.0.mlp.down_proj'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sublayer_name = 'mlp.down_proj'\n",
    "layer_index = 0\n",
    "\n",
    "key = f'model.layers.{layer_index}.{sublayer_name}'\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f0f20d8-a77b-420c-a1da-cfb7b0be3d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "quant_aqlm_config = literal_eval(requests.get(\n",
    "    'https://gist.githubusercontent.com/galqiwi/7c231a815da694fbcf374ebca14fb15f/raw/b894055c406fe9290e90d7dbc20ebd16335de5e9/optimal_3bit_aqlm'\n",
    ").text)\n",
    "\n",
    "quant_aqlm_config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15009f-cf34-4854-bcca-e49d5aaabf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78aaee-6949-43db-81de-554b13ad265f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
