{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3f6b82-f9c9-41ad-bfd3-7c3c96c643f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n",
      "env: OMP_NUM_THREADS=16\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "%env OMP_NUM_THREADS=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f205468-18d1-4a22-9d32-84ec0c805662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fbd6050e600>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5700d2-e535-433b-8dd7-685d04f03cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_hadamard_transform import hadamard_transform\n",
    "\n",
    "class NoisyHadamarLinear(torch.nn.Module):\n",
    "    def __init__(self, weight, bias, *, had_block_size = 2048, relative_mse = 0):\n",
    "        super().__init__()\n",
    "\n",
    "        weight = weight.detach().clone()\n",
    "        if bias is not None:\n",
    "            bias = bias.detach().clone()\n",
    "\n",
    "        self.had_block_size = had_block_size\n",
    "\n",
    "        self.out_features, self.in_features = weight.shape\n",
    "\n",
    "        self.inner = torch.nn.Linear(self.in_features, self.out_features, bias=(bias is not None), dtype=weight.dtype,\n",
    "                                     device=weight.device)\n",
    "\n",
    "        assert self.in_features % self.had_block_size == 0, (self.in_features, self.had_block_size)\n",
    "        weight = weight.reshape(self.out_features, self.in_features // self.had_block_size, self.had_block_size)\n",
    "        weight = hadamard_transform(weight, scale=1 / (self.had_block_size ** 0.5))\n",
    "        weight = weight.reshape(self.out_features, self.in_features)\n",
    "\n",
    "        weight = weight + torch.randn_like(weight) * torch.norm(weight) * (relative_mse ** 0.5) / (weight.numel() ** 0.5)\n",
    "\n",
    "\n",
    "\n",
    "        self.inner.weight.data = weight\n",
    "        if bias is not None:\n",
    "            self.inner.bias.data = bias\n",
    "\n",
    "    def forward(self, input):\n",
    "        input_shape = input.shape\n",
    "\n",
    "        assert input.shape[-1] % self.had_block_size == 0\n",
    "\n",
    "        input = input.reshape(-1, self.had_block_size)\n",
    "        input = hadamard_transform(input, scale=1 / (self.had_block_size ** 0.5))\n",
    "        input = input.reshape(input_shape)\n",
    "\n",
    "        return self.inner(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ee57a6-6ee0-4e20-b514-985c2dec0b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3071ba4bb8e5424c881de5cd6372ee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "MODEL_PATH = '/mnt/LLM/hub/models--meta-llama--Meta-Llama-3.1-8B/snapshots/13f04ed6f85ef2aa2fd11b960a275c3e31a8069e/'\n",
    "MODEL_SEQLEN = 8192\n",
    "BASE_PPL = 5.606692790985107\n",
    "\n",
    "model_pt_orig = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True, torch_dtype=\"auto\", device_map='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bc8131-9184-4455-bb40-1d216aaac254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (289076 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from eval import *\n",
    "\n",
    "testloader = get_loaders(\n",
    "    'wikitext2',\n",
    "    seed=0,\n",
    "    model_path=MODEL_PATH,\n",
    "    seqlen=MODEL_SEQLEN,\n",
    "    eval_mode=True,\n",
    "    use_fast_tokenizer=False,\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "\n",
    "def eval_ppl(\n",
    "    model,\n",
    "    model_path=MODEL_PATH,\n",
    "    model_seqlen=MODEL_SEQLEN,\n",
    "    device = 'cuda:0',\n",
    "    # ppl_datasets = ('wikitext2',),\n",
    "    trust_remote_code=False,\n",
    "    offload_activations=False,\n",
    "):\n",
    "    output = {}\n",
    "    \n",
    "    ppl = perplexity_eval(\n",
    "        model,\n",
    "        testloader,\n",
    "        dataset_name='wikitext2',\n",
    "        model_seqlen=model_seqlen,\n",
    "        device=device,\n",
    "        offload_activations=offload_activations,\n",
    "    )\n",
    "    output['wikitext2'] = ppl\n",
    "    # make sure that the cache is released\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5add09d8-4b7e-4db7-89ee-0fe9fbb7ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "\n",
    "NF4_CODES = torch.tensor([\n",
    "    -1.0, -0.6961928009986877, -0.5250730514526367, -0.39491748809814453, -0.28444138169288635, -0.18477343022823334,\n",
    "    -0.09105003625154495, 0.0,\n",
    "    0.07958029955625534, 0.16093020141124725, 0.24611230194568634, 0.33791524171829224, 0.44070982933044434,\n",
    "    0.5626170039176941, 0.7229568362236023, 1.0,\n",
    "], dtype=torch.float16)\n",
    "\n",
    "\n",
    "def get_closest_idx(x, grid):\n",
    "    _grid_len, = grid.shape\n",
    "    input_shape = x.shape\n",
    "    x = x.reshape(-1)\n",
    "\n",
    "    output = (x[:, None] - grid[None, :]).abs().min(dim=1).indices\n",
    "    assert output.shape == x.shape\n",
    "\n",
    "    return output.reshape(input_shape)\n",
    "\n",
    "\n",
    "def quantize_weight(weight, block_size=64, codes=NF4_CODES):\n",
    "    out_dim, in_dim = weight.shape\n",
    "    \n",
    "    codes = copy.deepcopy(codes).to(weight.device)\n",
    "\n",
    "    weight_groups = weight.reshape(-1, block_size)\n",
    "\n",
    "    scales = weight_groups.abs().max(dim=1).values\n",
    "\n",
    "    assert scales.shape == (out_dim * in_dim // block_size,)\n",
    "    weight_quantized = get_closest_idx(\n",
    "        weight_groups / scales[:, None],\n",
    "        codes,\n",
    "    ).reshape(out_dim, in_dim).to(weight.device)\n",
    "\n",
    "    return weight_quantized, scales\n",
    "\n",
    "\n",
    "def dequantize_weight(weight_quantized, scales, block_size = 64, codes=NF4_CODES):\n",
    "    out_dim, in_dim = weight_quantized.shape\n",
    "    \n",
    "    codes = copy.deepcopy(codes).to(weight_quantized.device)\n",
    "\n",
    "    return (\n",
    "        codes[weight_quantized].reshape(-1, block_size) *\n",
    "        scales[:, None]\n",
    "    ).reshape(out_dim, in_dim)\n",
    "\n",
    "\n",
    "def quantize_dequantize_weight(weight, block_size=64, codes=NF4_CODES):\n",
    "    weight_quantized, scales = quantize_weight(weight, block_size=block_size, codes=codes)\n",
    "    scales = scales.half()\n",
    "    return dequantize_weight(weight_quantized, scales, block_size=block_size, codes=codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a485a42-a453-49a7-9476-ba89ec354f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_by_path(model, path):\n",
    "    if path == '':\n",
    "        return model\n",
    "    splitted = path.split('.', 1)\n",
    "    if len(splitted) == 1:\n",
    "        splitted.append('')\n",
    "    next_name, suffix = splitted\n",
    "\n",
    "    try:\n",
    "        next_module = model[int(next_name)]\n",
    "    except:\n",
    "        next_module = getattr(model, next_name)\n",
    "\n",
    "    return get_module_by_path(next_module, suffix)\n",
    "\n",
    "def set_module_by_path(model, path, value):\n",
    "    parts = path.split('.')\n",
    "    prefix = '.'.join(parts[:-1])\n",
    "    parent = get_module_by_path(model, prefix)\n",
    "    setattr(parent, parts[-1], value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17edaeb-770c-447e-b0bd-525c6d1a765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = sorted([\n",
    "    name for name, value in\n",
    "    model_pt_orig.named_modules() if (\n",
    "        isinstance(value, nn.Linear) and\n",
    "        name.startswith('model.layers')\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9242320-4d8d-4d3b-a548-43b7c21bd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt_orig = model_pt_orig.half().cuda()\n",
    "# eval_ppl(model_pt_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d01a51-92e7-4747-8ebf-955719c72052",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4 = [-1.0, -0.6961928009986877, -0.5250730514526367, -0.39491748809814453, -0.28444138169288635, -0.18477343022823334, -0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725, 0.24611230194568634, 0.33791524171829224, 0.44070982933044434, 0.5626170039176941, 0.7229568362236023, 1.0]\n",
    "\n",
    "nf4 = torch.tensor(nf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c2c72d-17be-4785-95e0-cc68a8689946",
   "metadata": {},
   "outputs": [],
   "source": [
    "af4 = [-1.0, -0.7538047432899475, -0.5884406566619873, -0.4564161002635956, -0.34217405319213867, -0.23839078843593597, -0.14082424342632294, -0.04659047722816467, 0.04659047722816467, 0.14082424342632294, 0.23839078843593597, 0.34217405319213867, 0.4564161002635956, 0.5884406566619873, 0.7538047432899475, 1.0]\n",
    "\n",
    "af4 = torch.tensor(af4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642911f7-5ab3-49e2-b39a-53a550dc3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "eden = [-1.0, -0.7571635522922257, -0.5921293132333142, -0.459721873596143, -0.34485254078744687, -0.24034312562105065, -0.14200753146729223, -0.046986576840512384, 0.046986576840512384, 0.14200753146729223, 0.24034312562105065, 0.34485254078744687, 0.459721873596143, 0.5921293132333142, 0.7571635522922257, 1.0]\n",
    "\n",
    "eden = torch.tensor(eden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca8b668-11c7-4b60-a447-4e2522104109",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_by_name = {\n",
    "    'nf4': nf4,\n",
    "    'af4': af4,\n",
    "    'eden': eden,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0d953c-59ca-4fa1-a3a6-b762b43a5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "\n",
    "def eval_ppl_increase(codes, do_hadamar):\n",
    "    global model_pt_orig\n",
    "    model_pt_orig = model_pt_orig.float().cuda()\n",
    "    model_pt = copy.deepcopy(model_pt_orig).cuda()\n",
    "    \n",
    "    for layer in layers:\n",
    "        linear = get_module_by_path(model_pt, layer)\n",
    "\n",
    "        if do_hadamar:\n",
    "            new_linear = NoisyHadamarLinear(linear.weight, linear.bias)\n",
    "            new_linear.inner.weight.data = quantize_dequantize_weight(new_linear.inner.weight, codes=codes).cuda()\n",
    "            set_module_by_path(model_pt, layer, new_linear)\n",
    "            continue\n",
    "            \n",
    "        linear.weight.data = quantize_dequantize_weight(linear.weight, codes=codes).cuda()        \n",
    "    \n",
    "    model_pt = model_pt.half().cuda()\n",
    "    return eval_ppl(model_pt)['wikitext2'] - BASE_PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934a2c6-76c1-4975-8354-263c4008ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af4+hadamar 0.40107011795043945\n",
      "eden+hadamar 0.3985562324523926\n",
      "nf4+hadamar 0.4387364387512207\n"
     ]
    }
   ],
   "source": [
    "for do_hadamar in (True, False):\n",
    "    for name, codes in sorted(codes_by_name.items()):\n",
    "        print(\n",
    "            f'{name}+hadamar' if do_hadamar else name,\n",
    "            eval_ppl_increase(codes, do_hadamar),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b80fcc-486c-45cf-bb4b-7e4a3e89c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# af4 0.5006189346313477\n",
    "# eden 0.5040278434753418\n",
    "# nf4 0.35964202880859375\n",
    "# af4+hadamar 0.40241146087646484\n",
    "# eden+hadamar 0.40056753158569336\n",
    "# nf4+hadamar 0.41819286346435547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792ca49-c718-44a7-80bf-f90e32110708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pt(torch.tensor([0])[:, None].cuda());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280bc7f-c21c-4eb4-a1ad-0aa4b447bd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef643fd4-ff10-4c4b-befa-41aff99a227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add *.ipynb *.png *.csv *.py && git commit -m upd && git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
